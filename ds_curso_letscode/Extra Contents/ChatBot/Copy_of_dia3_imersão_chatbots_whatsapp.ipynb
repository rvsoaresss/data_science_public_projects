{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKTCwGJ8clLa"
   },
   "source": [
    "#NLP(Processamento de Linguagem Natural)\n",
    "---\n",
    "No BOOTCAMP CHATBOTS PARA WHATSAPP aprofundamos os conhecimentos com aprofundamento em Expressões Regulares(Regex)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbs9dRA8fIk6"
   },
   "source": [
    "## Passo 1 - Tokenization\n",
    "---\n",
    "Ato de separar sentenças, palavras, tweets em pedaços menores(chunks) para maior assertividade de semântica ou remoção de palavras indesejadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loQRn9eGcbZs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'me', 'chamo', 'Antônio']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"Olá, me chamo Antônio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoPwjJQ8iJTh"
   },
   "source": [
    "## Passo 2 - Bag-of-Words\n",
    "---\n",
    "Contagem de palavras para que o algoritmo encontre a importância de cada token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq4zsX6XiQ8g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Antônio': 3,\n",
       "         'ama': 1,\n",
       "         'programação': 2,\n",
       "         '.': 2,\n",
       "         'adora': 1,\n",
       "         'Python': 1,\n",
       "         'prefere': 1,\n",
       "         'orientada': 1,\n",
       "         'a': 1,\n",
       "         'objetos': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "frase = \"Antônio ama programação. Antônio adora Python. Antônio prefere programação orientada a objetos\"\n",
    "Counter(word_tokenize(frase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geh_CgVXjeG8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Antônio', 3), ('programação', 2)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(frase)).most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-aBKMgMgKfC"
   },
   "source": [
    "## Passo 3 - Stopwords\n",
    "---\n",
    "Ato de remover palavras indesejadas. Exemplo: artigos ou palavras que não trazem consigo apelo relacionado a gramática ou semântica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1hKVVOipIif"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soaresdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\soaresdo\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antônio', 'ama', 'a', 'programação', '.', 'Antônio', 'adora', 'o', 'Python', '.', 'Antônio', 'prefere', 'a', 'programação', 'orientada', 'a', 'objetos', '.']\n",
      "['Antônio', 'ama', 'programação', '.', 'Antônio', 'adora', 'Python', '.', 'Antônio', 'prefere', 'programação', 'orientada', 'objetos', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    " \n",
    "frase = \"Antônio ama a programação. Antônio adora o Python. Antônio prefere a programação orientada a objetos.\"\n",
    "stopwords = set(stopwords.words('portuguese')) \n",
    "word_tokens = word_tokenize(frase) \n",
    "\n",
    "limpas = [w for w in word_tokens if not w in stopwords] \n",
    "limpas = []\n",
    "\n",
    "for w in word_tokens: \n",
    "    if w not in stopwords: \n",
    "        limpas.append(w) \n",
    "\n",
    "print(word_tokens) \n",
    "print(limpas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DALgE1MlnfjB"
   },
   "source": [
    "Obs.: No BOOTCAMP CHATBOTS PARA WHATSAPP executamos todo pipeline NLP, além de aprofundamento no pré-processamento dos textos e diversas outras funções dentro do nltk e outras biblitoecas bastante relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4i1VpRRDctfx"
   },
   "source": [
    "#Criando seu primeiro Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjv81GHUcuAH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chatterbot in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: sqlalchemy<1.3,>=1.2 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (1.2.19)\n",
      "Requirement already satisfied: pint>=0.8.1 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (0.9)\n",
      "Requirement already satisfied: python-dateutil<2.8,>=2.7 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (2.7.5)\n",
      "Requirement already satisfied: spacy<2.2,>=2.1 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (2.1.9)\n",
      "Requirement already satisfied: pytz in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (2019.2)\n",
      "Requirement already satisfied: nltk<4.0,>=3.2 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (3.4.5)\n",
      "Requirement already satisfied: mathparse<0.2,>=0.1 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (0.1.2)\n",
      "Requirement already satisfied: pymongo<4.0,>=3.3 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from chatterbot) (3.9.0)\n",
      "Collecting pyyaml<5.2,>=5.1\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/3f/4f733cd0b1b675f34beb290d465a65e0f06b492c00b111d1b75125062de1/PyYAML-5.1.2-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from python-dateutil<2.8,>=2.7->chatterbot) (1.12.0)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (2.0.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (0.3.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (1.17.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (1.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (0.2.4)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from spacy<2.2,>=2.1->chatterbot) (7.0.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.2,>=2.1->chatterbot) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from thinc<7.1.0,>=7.0.8->spacy<2.2,>=2.1->chatterbot) (4.37.0)\n",
      "Installing collected packages: pyyaml\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed pyyaml-5.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: chatterbot-corpus 1.2.0 has requirement PyYAML<4.0,>=3.12, but you'll have pyyaml 5.1.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chatterbot_corpus in c:\\users\\soaresdo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.2.0)\n",
      "Collecting PyYAML<4.0,>=3.12\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/96/d02ef8e1f3073e07ffdc240444e5041f403f29c0775f9f1653f18221082f/PyYAML-3.13-cp37-cp37m-win_amd64.whl\n",
      "Installing collected packages: PyYAML\n",
      "  Found existing installation: PyYAML 5.1.2\n",
      "    Uninstalling PyYAML-5.1.2:\n",
      "      Successfully uninstalled PyYAML-5.1.2\n",
      "Successfully installed PyYAML-3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: chatterbot 1.0.5 has requirement pyyaml<5.2,>=5.1, but you'll have pyyaml 3.13 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chatterbot\n",
    "!pip install chatterbot_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7Bt3z_-j1dN"
   },
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5q_nynzPkeXt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training compliment.yml: [                    ] 2%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\soaresdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soaresdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training compliment.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training linguistic_knowledge.yml: [####################] 100%\n",
      "Training proverbs.yml: [####################] 100%\n",
      "Training suggestions.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training unilab.yml: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot(\"Ananda\")\n",
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "trainer.train(\"chatterbot.corpus.portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpArG4pVlUNn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n",
      "Como vai você?\n",
      "t\n",
      "Quais linguagens você gosta de usar?\n",
      "t\n",
      "Olá\n",
      "g\n",
      "Bom Dia como você está?\n",
      "d\n",
      "eu sei\n",
      "w\n",
      "g\n",
      "f\n",
      "você também fala bem\n",
      "a\n",
      "eu sei\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  try:\n",
    "      bot_input = chatbot.get_response(input())\n",
    "      print(bot_input)\n",
    "  except:\n",
    "    print(\"Algo deu errado... Tchau!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7pl7HNCnHiM"
   },
   "source": [
    "No BOOTCAMP CHATBOTS PARA WHATSAPP nos aprofundamos nesta e em outras bibliotecas, ativando por exemplo adaptadores lógicos e armazenamento dos conhecimentos, além da possibilidade de aprendizado contínuo da máquina e outros frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FKTCwGJ8clLa",
    "lbs9dRA8fIk6",
    "VoPwjJQ8iJTh",
    "6-aBKMgMgKfC",
    "4i1VpRRDctfx"
   ],
   "name": "Copy of dia3-imersão-chatbots-whatsapp.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
